{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22cbe8c8-82c7-4c25-a916-841fc52a3f75",
   "metadata": {},
   "source": [
    "## Natural Language Processing With Python's NLTK Package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82396a63-24a6-407b-b45b-186c50271cb4",
   "metadata": {},
   "source": [
    "##### To install NLTK with pip. It’s a best practice to install it in a virtual environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d673d16-fb5e-457a-aa31-8474cb9e2818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install nltk\n",
    "#pip install textblob \n",
    "#pip install pyspellchecker\n",
    "\n",
    "#nltk.download('punkt_tab')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('averaged_perceptron_tagger_eng')\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5513737a-b0a4-469f-922c-d3aef65b3020",
   "metadata": {},
   "source": [
    "### Step 1: Print the text\n",
    "#### Purpose: Set up the imports and print the text stored in example_text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7056ea5e-f8c9-4318-9fd4-8a1968ac9472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once you are FULLY vaccinated, you can traval in the United States without getting tested or self-quarantining after traveling. https://www.cdc.gov\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "example_text = \"Once you are FULLY vaccinated, you can traval in the United States without getting tested or self-quarantining after traveling. https://www.cdc.gov\"\n",
    "\n",
    "print(example_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeee722-769e-420f-804f-9c1b2788a6a9",
   "metadata": {},
   "source": [
    "### Step 2: URL Removal\n",
    "#### Purpose: Removes any substring starting with \"http\" followed by non-whitespace characters using regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f741333-d866-4146-bf72-4d07b4a6a309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once you are FULLY vaccinated, you can traval in the United States without getting tested or self-quarantining after traveling. \n"
     ]
    }
   ],
   "source": [
    "# Removal of URLs:\n",
    "def remove_url(text_data):\n",
    "    return re.sub(r\"http\\S+\", \"\", text_data)\n",
    "\n",
    "processed_text = remove_url(example_text)\n",
    "\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c51215-a224-411a-adb1-8321a897091f",
   "metadata": {},
   "source": [
    "### Step 3: Convert to Lowercase\n",
    "#### Purpose: Converts all characters to lowercase for standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72350e3f-6380-4f91-9599-81e7058d076f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "once you are fully vaccinated, you can traval in the united states without getting tested or self-quarantining after traveling. \n"
     ]
    }
   ],
   "source": [
    "# lowercases\n",
    "def lower_case(text_data):\n",
    "    return text_data.lower()\n",
    "\n",
    "lower = lower_case(processed_text)\n",
    "\n",
    "print(lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfaf324-6289-4a8b-a17e-acc97d678996",
   "metadata": {},
   "source": [
    "### Step 4: Spelling Correction\n",
    "#### Purpose: character-level spelling correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4667b92e-40fc-42d8-b38e-a062a7fb8b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "once you are fully vaccinated, you can travel in the united states without getting tested or self-quarantining after traveling. \n"
     ]
    }
   ],
   "source": [
    "# Spelling Correction\n",
    "# character-level spelling correction \n",
    "def correct_spelling(text):\n",
    "    return str(TextBlob(text).correct())\n",
    "\n",
    "processed_text = correct_spelling(lower)\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd52597b-4a45-43d2-b5ad-cd729392e199",
   "metadata": {},
   "source": [
    "### Step 5: Tokenization\n",
    "#### Purpose: Uses word_tokenize from NLTK to split the lowercase string into a list of word-level tokens, including punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "941bc3c1-6aa0-4b99-896e-fb87b2620c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['once', 'you', 'are', 'fully', 'vaccinated', ',', 'you', 'can', 'travel', 'in', 'the', 'united', 'states', 'without', 'getting', 'tested', 'or', 'self-quarantining', 'after', 'traveling', '.']\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "#import nltk\n",
    "#nltk.download('punkt_tab')\n",
    "\n",
    "def token(text_data):\n",
    "    return word_tokenize(text_data)\n",
    "\n",
    "word_tokens = token(processed_text)\n",
    "print(word_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7970f8-d6d0-4cae-be04-b83d147626d7",
   "metadata": {},
   "source": [
    "### Step 6: Stopword removal \n",
    "#### Purpose: Remove Stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "131e8a84-a7fb-4326-a8c4-695ed650228d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fully', 'vaccinated', ',', 'travel', 'united', 'states', 'without', 'getting', 'tested', 'self-quarantining', 'traveling', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "# Stopword Removal\n",
    "def remove_stopwords(tokens):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    return [w for w in tokens if w.lower() not in stop_words]\n",
    "\n",
    "filtered_tokens = remove_stopwords(word_tokens)\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bf1caf-0f6f-44bf-9973-cc4eb1ac09ab",
   "metadata": {},
   "source": [
    "### Step 7: Punctuation removal \n",
    "#### Purpose: Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "707d6955-6347-490f-a7e7-57fc3ad0f141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fully', 'vaccinated', 'travel', 'united', 'states', 'without', 'getting', 'tested', 'self-quarantining', 'traveling']\n"
     ]
    }
   ],
   "source": [
    "# Punctuation Removal\n",
    "def remove_punctuation(tokens):\n",
    "    return [w for w in tokens if w not in string.punctuation]\n",
    "\n",
    "clean_tokens = remove_punctuation(filtered_tokens)\n",
    "\n",
    "print(clean_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7915446c-7060-42c1-a01b-761033a9c796",
   "metadata": {},
   "source": [
    "### Step 8: Part-of-speech (POS) tagging\n",
    "#### Purpose: Assign POS tags to each word (token) in a list of tokens using NLTK’s pos_tag() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68d67a9c-750a-4788-9008-f9b6b89bdb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('fully', 'RB'), ('vaccinated', 'VBN'), ('travel', 'NN'), ('united', 'JJ'), ('states', 'NNS'), ('without', 'IN'), ('getting', 'VBG'), ('tested', 'VBN'), ('self-quarantining', 'JJ'), ('traveling', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# Part of speech tagging\n",
    "def part_of_speech(text_data):\n",
    "    return nltk.pos_tag(text_data)\n",
    "\n",
    "tags = nltk.pos_tag(clean_tokens)\n",
    "\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6c7cc4-5e88-43de-aea8-67b413d4b19a",
   "metadata": {},
   "source": [
    "What POS Tagging Does? \n",
    "\n",
    "It helps identify the grammatical role of each word, such as:\n",
    "\n",
    "    'NN' = Noun (e.g., \"traval\")\n",
    "\n",
    "    'JJ' = Adjective (e.g., \"vaccinated\")\n",
    "\n",
    "    'VBG' = Verb Gerund (e.g., \"getting\")\n",
    "\n",
    "    'RB' = Adverb (e.g., \"fully\")\n",
    "\n",
    "    'IN' = Preposition (e.g., \"without\")\n",
    "\n",
    "    'NNS' = Plural Noun (e.g., \"states\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d493684f-ac85-4fa7-a0da-4e2ab6296783",
   "metadata": {},
   "source": [
    "### Step 9: Lemmatization Using POS Tags\n",
    "#### Purpose: Lemmatization based on part-of-speech (POS) tags for each word (token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2b6ce71-d659-45ad-8dfb-2ff57fa37d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fully               lemma =>            fully               \n",
      "vaccinated          lemma =>            vaccinate           \n",
      "travel              lemma =>            travel              \n",
      "united              lemma =>            united              \n",
      "states              lemma =>            state               \n",
      "without             lemma =>            without             \n",
      "getting             lemma =>            get                 \n",
      "tested              lemma =>            test                \n",
      "self-quarantining   lemma =>            self-quarantining   \n",
      "traveling           lemma =>            traveling           \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from collections import defaultdict\n",
    "\n",
    "def pos_lemm(text_data):\n",
    "    tag_map = defaultdict(lambda: wn.NOUN)\n",
    "    tag_map['J'] = wn.ADJ\n",
    "    tag_map['V'] = wn.VERB\n",
    "    tag_map['R'] = wn.ADV\n",
    "\n",
    "    lemtzr = WordNetLemmatizer()\n",
    "\n",
    "    for token, tag in pos_tag(text_data):\n",
    "        lemma = lemtzr.lemmatize(token, tag_map[tag[0]])\n",
    "        print(\"{0:20}{1:20}{2:20}\".format(token, \"lemma =>\", lemma))\n",
    "\n",
    "print(pos_lemm(clean_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9977db-9cec-4968-8b2f-86d6395d5a56",
   "metadata": {},
   "source": [
    "## Typical Next Steps After Lemmatization\n",
    "1. Text Vectorization – Convert text to numbers for machine learning. Choose based on model requirements:\n",
    "\n",
    "| Method              | Description                               | Use Case                  |\n",
    "| ------------------- | ----------------------------------------- | ------------------------- |\n",
    "| `CountVectorizer`   | Bag-of-Words (word frequency)             | Basic ML models           |\n",
    "| `TfidfVectorizer`   | Term frequency-inverse document frequency | More meaningful weighting |\n",
    "| `Word2Vec`, `GloVe` | Dense vector embeddings                   | Semantic meaning          |\n",
    "| `BERT`, `GPT`, etc. | Contextual embeddings                     | Deep NLP (transformers)   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf78e6a-1a61-4931-a3d8-6703fca154d5",
   "metadata": {},
   "source": [
    "2. Modeling or Analysis. Now you're ready for your main NLP task, such as:\n",
    "\n",
    "    Classification (e.g., spam detection, sentiment analysis)\n",
    "\n",
    "    Clustering (e.g., topic modeling with LDA)\n",
    "\n",
    "    Named Entity Recognition\n",
    "\n",
    "    Summarization\n",
    "\n",
    "    Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94232bc-51d8-4cdf-a201-48883ab05546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
